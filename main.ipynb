{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9571bc-7b91-48f9-85c3-b77c85a16e41",
   "metadata": {},
   "source": [
    "# EfficientNet V1 From Scratch\n",
    "\n",
    "In this notebook I'll explore building an efficient net from scratch, following by an attempt to recreate the paper steps into achieving its final results.\n",
    "I think that I should go into this project through these steps to make it easy:\n",
    "\n",
    "- [ ]  Implement an MBConv layer\n",
    "- [ ]  Implement an efficientnet baseline\n",
    "- [ ]  Test efficientnet on fastai imagenette using paper configuration and compare with resent\n",
    "- [ ]  Implement neural architecture search \n",
    "\n",
    "\n",
    "EfficientNets are similar to ResNets in that they consist of bottleneck layers. However, EfficientNets use <strong>MBConv (Mobile Inverted Bottleneck Convolutional Blocks)</strong> followed by <strong>SEBlocks (Squeeze and Excitation Blocks)</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cad65-b757-4e1c-81d1-6acbd85aca0a",
   "metadata": {},
   "source": [
    "## MBConv block\n",
    "### What is an MBConv block?\n",
    "\n",
    "An MBConv block is the building block of MobileNetV2, and here is an excerpt from the MobilNetV2 papers describing it.\n",
    "\n",
    "> Our network pushes the state\n",
    "of the art for mobile tailored computer vision models,\n",
    "by significantly decreasing the number of operations and\n",
    "memory needed while retaining the same accuracy.\n",
    "\n",
    "An MBConv layer module is an <strong><em>inverted residual with linear bottleneck</em></strong>.\n",
    "\n",
    "This definition needs a little bit of dissection. First let's take a look at a residual block.\n",
    "\n",
    "![residual block](https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)\n",
    "\n",
    "A residual block (bottleneck layer) is a module which basically adds it's input to the final output of the block. We can see that it has ReLU non-linearity, and in the ResNet architecture, the number of channels generally tends to expand, and inside the block the bottleneck occures in decreasing the channels, then increasing it back again.\n",
    "\n",
    "![resnet](https://www.researchgate.net/publication/336642248/figure/fig1/AS:839151377203201@1577080687133/Original-ResNet-18-Architecture.png)\n",
    "\n",
    "#### So how does an MBConv differ from Residual Block?\n",
    "\n",
    "1. Channels depth increases within the block then they decrease upon output \n",
    "2. ReLU isn't used in the output layer and only used within the expansion zone\n",
    "\n",
    "<img src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_10.08.25_PM.png\" width=\"400\" align=\"center\" />\n",
    "\n",
    "### Why use an MBConv Layer?\n",
    "\n",
    "1. More efficient\n",
    "2. Reduce computational time\n",
    "\n",
    "### Now let's implement it using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21887f32-0958-442a-9288-f7edac0b69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from torch.nn.modules.activation import ReLU6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e4b85-1c94-402e-b3bf-40056681ff0b",
   "metadata": {},
   "source": [
    "First let's make only the bottleneck convolutional layer. According to the paper it should be like that:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*mFKsFp9fi8LDaflCu8Tyhg@2x.png\" width=\"400px\" align=\"center\"/>\n",
    "\n",
    "This translate to:\n",
    "1. A 1x1 convolutional layer to expand the depth of the input image without decreaseing the width and height with a ReLU6 non-linearity\n",
    "2. A 3x3 convolutional layer to decrease the dimensions of the previous layer output while keeping the expanded depth with a ReLU6 non-linearity\n",
    "3. A 1x1 convolutional layer to shrink the depth last layer output without applying a non-linear function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09a8825-c864-4d0f-a6cd-3c41bb98f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBlock(Module):\n",
    "    def __init__(self, ni, nf, ks=3, stride=1, t=6):\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayer(ni, ni*6, ks=1, act_cls=ReLU6),\n",
    "            ConvLayer(ni*6, ni*6, ks=ks, stride=stride, act_cls=ReLU6),\n",
    "            ConvLayer(ni*6, nf, ks=1, act_cls=None)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ad075-112c-4e3c-bfd0-e3cfb40a01c1",
   "metadata": {},
   "source": [
    "To test this block, I'll make an input tensor to check the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdbd982-9c71-4c5a-9725-61cb52e83fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand((1, 3))\n",
    "w[..., None, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943f70e3-4d1a-4741-a966-35e9027ba57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.rand((1, 3, 28, 28))\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a65ac3-2663-48cb-b74b-383e4b84b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbconv = MBConvBlock(3, 6, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d9c35f-1f05-4d67-98d3-84d344106219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "output_tensor = mbconv(input_tensor)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bbda1-5de7-46db-926b-6644a41ffcda",
   "metadata": {},
   "source": [
    "Now we have to add two things to this class:\n",
    "1. An average pooling layer if the stride 2 is used\n",
    "2. An 1x1 convolutional layer to convert the input tensor depth to the output tensor depth for addition\n",
    "3. A squeeze and excitation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5ee602-37d5-4f11-a2fa-6f921044c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Sequential):\n",
    "    def __init__(self, ni, r=8):\n",
    "        super().__init__(*[\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Flatten(),\n",
    "            nn.Linear(ni, ni//r),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ni//r, ni),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "\n",
    "class MBConvBlock(Module):\n",
    "    def __init__(self, ni, nf, ks=3, stride=1, t=6, r=16):\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayer(ni, ni*6, ks=1, act_cls=ReLU6),\n",
    "            ConvLayer(ni*6, ni*6, ks=ks, stride=stride, act_cls=ReLU6),\n",
    "            ConvLayer(ni*6, nf, ks=1, act_cls=None)\n",
    "        )\n",
    "        self.pool = noop if stride == 1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "        self.idconv = noop if ni == nf else ConvLayer(ni, nf, ks=1, act_cls=None)\n",
    "        self.seblock = SEBlock(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv_out = self.convs(x)\n",
    "        w = self.seblock(conv_out)\n",
    "        return conv_out*w[..., None, None] + self.idconv(self.pool(x))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efad6cce-86ea-4d63-935f-0c9271950be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/init.py:398: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 14, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbconv = MBConvBlock(3, 6, stride=2)\n",
    "mbconv(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930a5c9-30cd-43b6-94e6-c9404d223103",
   "metadata": {},
   "source": [
    "Now that we have a working MBConv layer, let's proceed to build the baseline efficientnet b0.\n",
    "\n",
    "I'll build this at first without any compound scaling capability.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/0*6ezHy0HX_lCrJGRS\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb7177f-866a-4d63-b91d-d7df4693a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB0(nn.Sequential):\n",
    "    def __init__(self, n_out, layers):\n",
    "        stem = ConvLayer(ni=3, nf=32, ks=3, stride=1)\n",
    "        self.block_szs = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "        self.block_ks = [3, 3, 5, 3, 5, 5, 3]\n",
    "        self.block_ts = [1] + [6]*6\n",
    "        self.strides = [2, 1, 2, 2, 2, 1, 2]\n",
    "        \n",
    "        blocks = [self._make_layer(*o) for o in enumerate(layers)]\n",
    "        super().__init__(*stem, *blocks, \n",
    "                         ConvLayer(self.block_szs[-2], self.block_szs[-1], ks=1),\n",
    "                         nn.AdaptiveAvgPool2d(1), Flatten(),\n",
    "                         nn.Linear(self.block_szs[-1], n_out))\n",
    "        \n",
    "    def _make_layer(self, i, n_layers):\n",
    "        ni, nf = self.block_szs[i], self.block_szs[i+1]\n",
    "        ks, t = self.block_ks[i], self.block_ts[i]\n",
    "        stride = self.strides[i]\n",
    "        \n",
    "        return nn.Sequential(*[\n",
    "            MBConvBlock(ni if i == 0 else nf, nf, ks, stride, t)\n",
    "            for i in range(n_layers)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8391e3c-5882-4a1b-9b85-ef1736b9d7f8",
   "metadata": {},
   "source": [
    "Now let's make a model and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabeb381-93ca-4ff5-845c-439501edac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(10, layers=[1, 2, 2, 3, 3, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64323a9d-1c6c-4729-84c2-a9ef760653f9",
   "metadata": {},
   "source": [
    "Now let's test this model on fastai's Imagenette, and then compare it to ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe957f6-4143-454b-aa72-6b209f9379b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8157ae-dc42-4b59-b9a8-78a82b2539d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(path, valid='val', \n",
    "    item_tfms=Resize(160), batch_tfms=[*aug_transforms(size=128, min_scale=0.5), Normalize.from_stats(*imagenet_stats)], bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2d91e4-5927-4c12-9717-8e60272bde2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddda86bf-f97d-453d-a8c4-ed665e601191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.828946</td>\n",
       "      <td>3.050071</td>\n",
       "      <td>0.235924</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.722414</td>\n",
       "      <td>1.688316</td>\n",
       "      <td>0.409936</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.391298</td>\n",
       "      <td>1.334921</td>\n",
       "      <td>0.572484</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.153258</td>\n",
       "      <td>1.112591</td>\n",
       "      <td>0.645350</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.989492</td>\n",
       "      <td>1.030246</td>\n",
       "      <td>0.660892</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eff_learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8066d804-1a03-4cdf-9981-274afb060865",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_learn = cnn_learner(dls, resnet50, pretrained=False, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a3936c-694b-45ad-b56f-e1347e318172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.543627</td>\n",
       "      <td>2.300174</td>\n",
       "      <td>0.340382</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.048752</td>\n",
       "      <td>1.691249</td>\n",
       "      <td>0.417325</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.732282</td>\n",
       "      <td>1.517511</td>\n",
       "      <td>0.515669</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.446873</td>\n",
       "      <td>1.332534</td>\n",
       "      <td>0.589554</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.226360</td>\n",
       "      <td>1.112935</td>\n",
       "      <td>0.661401</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a2d03-ac11-4b12-a96e-6074e826f353",
   "metadata": {},
   "source": [
    "You can see that my implementation of EfficientNet-B0 is similar to ResNet-50 performance wise, but it's still slower than ResNet-50, which means that there is something not right in my implementation, since EfficientNet-b0 is supposed to be faster than ResNet-50."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
